<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

    <title>HyunJin, Kim</title>

    <link rel="stylesheet" href="/assets/styles/github-light.css">
    <link rel="stylesheet" href="/assets/styles/personal.css">
</head>

<body>
    <div class="container">
        <header>
            <h1>HyunJin, Kim</h1>
            <img src="/assets/images/members/HJK.jpg" style="width:190px;"><br />
            <p>Ph.D. Student<br />
<a href="https://hli.skku.edu">HLI Lab</a>, <a href="https://www.skku.edu/">SKKU</a></p>
<p><a href="mailto:khyunjin1993@g.skku.edu">Email</a> / <a href="https://khyunjin1993.medium.com/">Medium</a> / <a href="https://github.com/agwaBom">GitHub</a></p>
        </header>

        <section class="content">
            
            <h2>About</h2>
<p>I am a Ph.D. student at Sungkyunkwan University (SKKU), advised by Professor JinYeong Bak in the Human Language Intelligence Lab. </p>
<p>Concurrently, I am participating in the Ph.D. Collaborator program with Microsoft Research.<br />
In collaboration with Dr. Young Jin Kim, I am exploring effective fine-tuning techniques for a generative model.  </p>
<p>My research focuses on natural language processing, parameter-efficient fine-tuning, retrieval augmented generation, and the analysis of deep learning models.</p>
            
            <h2>Education</h2>
<ul>
<li><strong>Sungkyunkwan University</strong>, South Korea.<br />
  Ph.D., Artificial Intelligence, 2023~Present</li>
<li><strong>Sungkyunkwan University</strong>, South Korea.<br />
  M.S., Artificial Intelligence, 2021~2023</li>
<li><strong>Kyonggi University</strong>, South Korea.<br />
  B.S., Computer Engineering (Transferred), 2019~2021<br />
  B.S., Early Childhood Education, 2015~2019</li>
</ul>
            
            <h2>International Conferences and Journals</h2>
<ol>
<li>
<p><strong>PEMA: Plug-in External Memory Adaptation for Language Models</strong><br />
<strong>HyunJin Kim</strong>, Young Jin Kim, JinYeong Bak<br />
  (NAACL 2024;To appear).<br />
<a href="https://arxiv.org/abs/2311.08590">Preprint</a></p>
</li>
<li>
<p><strong>A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing</strong><br />
<strong>HyunJin Kim</strong>, JinYeong Bak, Kyunghyun Cho, and Hyungjoon Koo<br />
  [In the 18th ACM Asia Conference on Computer and Communications Security] 2023.<br />
<a href="https://dl.acm.org/doi/abs/10.1145/3579856.3582823">PDF</a>
  <a href="https://github.com/agwaBom/AsmDepictor">Code</a></p>
</li>
<li>
<p><strong>Associative Knowledge Graph Using Fuzzy Clustering and Min-Max Normalization in Video Contents</strong><br />
<strong>Hyun-Jin Kim</strong>, Ji-Won Baek, Kyungyong Chung<br />
  [IEEE Access] 2021.<br />
<a href="https://ieeexplore.ieee.org/document/9430567">Link</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9430567">PDF</a>  </p>
</li>
</ol>
<h2>Domestic Conferences and Journals</h2>
<ol>
<li>
<p><strong>Function Name Prediction using Binary Code with Transformer</strong><br />
<strong>HyunJin Kim</strong> and JinYeong Bak<br />
  [The Korean Institute of Information Scientists and Engineers] 2021.</p>
</li>
<li>
<p><strong>Traffic Knowledge Graph using Associative Document Weight</strong><br />
<strong>Hyun-Jin Kim</strong>, Min-Jeong Kim, Ju-Chang Kim, Kyungyong Chung<br />
  [International Conference on Convergence Technology] 2020.</p>
</li>
<li>
<p><strong>Association Rule based Video Knowledge Extraction using Object Detection Algorithm</strong><br />
<strong>Hyun-Jin Kim</strong>, Hye-Jeong Kwon, Ji-Hye Gwon, Kyungyong Chung
  [Korean Society for Internet Information] 2020.  </p>
</li>
<li>
<p><strong>Data Bias Optimization based Association Reasoning Model for Road Risk Detection.</strong><br />
  Seong-Eun Ryu, <strong>Hyun-Jin Kim</strong>, Byung-Kook Koo, Hye-Jeong Kwon, Roy C Park, Kyungyong Chung<br />
  [Journal of the Korea Convergence Society] 2020.  </p>
</li>
</ol>
            
            <h2>Teaching Experience</h2>
<ul>
<li>
<p><strong>Open Source Software Practice</strong>, (SKKU)<br />
  Teaching Assistant {Spring 2023, Fall 2023}</p>
</li>
<li>
<p><strong>K-mooc : Mathematics for AI</strong>, (SKKU)<br />
  Dev Teaching Assistant (Summer 2021)</p>
</li>
</ul>
<h2>Talks</h2>
<ul>
<li>
<p><strong>A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing</strong><br />
  IBM Research, (Fall 2023)</p>
</li>
<li>
<p><strong>A Transformer-based Function Symbol Name Inference Model from an Assembly Language for Binary Reversing</strong><br />
  SKKU AI Colloquium, (Fall 2022)</p>
</li>
<li>
<p><strong>Function Name Prediction from Binary Code with Transformer</strong><br />
  New York University, (Fall 2021)</p>
</li>
</ul>
            
            <h2>Work Experience</h2>
<ul>
<li>Research Intern, <strong>Deargen Inc</strong>, (Summer, 2022)<br />
  I interned with Dr. Bonggun Shin in Deargen USA. I analyzed the differences in synthetic essentiality (SE) scores by inserting new fingerprint data into a cancer dependency prediction model that contains cancer cell lines (CCLs) with different mutation environments.</li>
</ul>
            
            <h2>Academic Services</h2>
<ul>
<li><strong>ACM FAccT 2022</strong><br />
  Student Vounteer</li>
</ul>
            
            <h2>Extracurricular Activities</h2>
<ul>
<li>
<p><strong>Optimistic, Pessimistic and Realistic of Large Language Models</strong><br />
  KOFST, Assistant, 2023</p>
</li>
<li>
<p><strong>State, Limitations, and Future of Large Language Models</strong><br />
  KOFST, Assistant, 2022</p>
</li>
</ul>
            
            <h2>Reference</h2>
<ul>
<li><strong>Prof. JinYeong, Bak</strong>, SKKU, jy.bak@skku.edu  </li>
<li><strong>Dr. Young Jin, Kim</strong>, Microsoft, youki@microsoft.com  </li>
<li><strong>Dr. Bonggun, Shin</strong>, Deargen-USA, bonggun.shin@deargen.me</li>
<li><strong>Prof. Kyungyong, Chung</strong>, KGU, dragonhci@daum.net  </li>
</ul>
            
        </section>
    </div>
</body>

</html>